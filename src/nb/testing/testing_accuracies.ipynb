{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "while \"src\" not in os.listdir():\n",
    "    assert \"/\" != os.getcwd(), \"src directory not found\"\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('simclr-pytorch')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.lib.nyu_dataset import NYUDataset, transform\n",
    "from src.lib.util import convert_depth_to_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(loader, label, loss_fn):\n",
    "    for name in models_map:\n",
    "        model = models_map[name][\"model\"].to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # calculate validation loss\n",
    "            loss = 0\n",
    "            for batch in loader:\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                loss += loss_fn(y_pred, y).item()\n",
    "            loss /= len(loader)\n",
    "            del x, y, y_pred\n",
    "        models_map[name][label] = loss\n",
    "    \n",
    "\n",
    "def get_absolute_errors(loader, label):\n",
    "    for name in models_map:\n",
    "        model = models_map[name][\"model\"].to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            errors = []\n",
    "            for batch in loader:\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                abs_err = torch.abs(y_pred - y).to(\"cpu\").numpy()\n",
    "                # flatten\n",
    "                abs_err = abs_err.reshape(-1)\n",
    "                errors.append(abs_err)\n",
    "            errors = np.concatenate(errors)\n",
    "            del x, y, y_pred\n",
    "        models_map[name][label] = errors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data\"\n",
    "DATASET_FILE = \"nyu_depth_v2_labeled.mat\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NYUDataset(os.path.join(DATA_DIR, DATASET_FILE), transform=transform)\n",
    "\n",
    "n_train, n_val = int(0.8 * len(dataset)), int(0.1 * len(dataset))\n",
    "n_test = len(dataset) - n_train - n_val\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "val_loader = DataLoader(val_set, batch_size=64, shuffle=True, num_workers=8)\n",
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_dir = \"experiments\"\n",
    "experiment_names = os.listdir(experiments_dir)\n",
    "\n",
    "models_map = {}\n",
    "for name in experiment_names:\n",
    "    # base_name = name[:-2]\n",
    "    model_path = os.path.join(experiments_dir, name, \"model.pth\")\n",
    "    models_map[name] = {\"model\": torch.load(model_path).to(\"cpu\")}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(models_map, loader, label):\n",
    "    \"\"\" modifies models_map\n",
    "        models_map[name][label_errors] = array of all errors for all pixels\n",
    "        models_map[name][label_loss] = MSE in meters over all data samples\n",
    "\n",
    "    Args:\n",
    "        loader (_type_): _description_\n",
    "        label (_type_): _description_\n",
    "    \"\"\"\n",
    "    stats = defaultdict(dict)\n",
    "    for name in models_map:\n",
    "        model = models_map[name][\"model\"].to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            errors = []\n",
    "            rel = []\n",
    "            loss = 0\n",
    "            for batch in loader:\n",
    "                x, y = batch\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                y_pred = model(x)\n",
    "                y_pred = convert_depth_to_m(y_pred)\n",
    "                y = convert_depth_to_m(y)\n",
    "\n",
    "                loss += torch.nn.functional.mse_loss(y_pred, y).item()\n",
    "\n",
    "                y_pred = y_pred.to(\"cpu\").numpy()\n",
    "                y = y.to(\"cpu\").numpy()\n",
    "\n",
    "                ratio = y / y_pred\n",
    "                ratio = ratio.reshape(-1)\n",
    "                errors.append(np.maximum(ratio, 1 / ratio))\n",
    "\n",
    "                rel_error = np.abs(y_pred - y) / y\n",
    "                rel_error = rel_error.reshape(-1)\n",
    "                rel.append(rel_error)\n",
    "\n",
    "\n",
    "                \n",
    "            errors = np.concatenate(errors)\n",
    "            rel = np.concatenate(rel)\n",
    "            del x, y, y_pred\n",
    "        stats[name][label + \"_errors\"] = errors\n",
    "        stats[name][label + \"_rel\"] = rel\n",
    "        stats[name][label + \"_loss\"] = loss / len(loader)\n",
    "    return stats\n",
    "\n",
    "stats = get_stats(models_map, test_loader, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss\tclassification finetuning:\t0.4121\n",
      "test_rel\tclassification finetuning:\t0.1775\n",
      "test_acc_1.25\tclassification finetuning:\t0.7442\n",
      "test_acc_1.5625\tclassification finetuning:\t0.9482\n",
      "test_acc_1.953125\tclassification finetuning:\t0.9886\n",
      "test_loss\tclassification probing:\t0.8462\n",
      "test_rel\tclassification probing:\t0.2453\n",
      "test_acc_1.25\tclassification probing:\t0.5536\n",
      "test_acc_1.5625\tclassification probing:\t0.8546\n",
      "test_acc_1.953125\tclassification probing:\t0.9593\n",
      "test_loss\tclassification switch:\t0.4599\n",
      "test_rel\tclassification switch:\t0.1832\n",
      "test_acc_1.25\tclassification switch:\t0.7135\n",
      "test_acc_1.5625\tclassification switch:\t0.9406\n",
      "test_acc_1.953125\tclassification switch:\t0.9868\n",
      "test_loss\tcontrastive finetuning:\t0.4786\n",
      "test_rel\tcontrastive finetuning:\t0.1895\n",
      "test_acc_1.25\tcontrastive finetuning:\t0.7037\n",
      "test_acc_1.5625\tcontrastive finetuning:\t0.9346\n",
      "test_acc_1.953125\tcontrastive finetuning:\t0.9866\n",
      "test_loss\tcontrastive probing:\t0.8140\n",
      "test_rel\tcontrastive probing:\t0.2655\n",
      "test_acc_1.25\tcontrastive probing:\t0.5656\n",
      "test_acc_1.5625\tcontrastive probing:\t0.8555\n",
      "test_acc_1.953125\tcontrastive probing:\t0.9545\n",
      "test_loss\tcontrastive switch:\t0.5705\n",
      "test_rel\tcontrastive switch:\t0.2099\n",
      "test_acc_1.25\tcontrastive switch:\t0.6629\n",
      "test_acc_1.5625\tcontrastive switch:\t0.9137\n",
      "test_acc_1.953125\tcontrastive switch:\t0.9788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bill/spring2022/674/2project/testenv/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/bill/spring2022/674/2project/testenv/lib/python3.10/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "thresholds = [1.25, 1.25**2, 1.25**3]\n",
    "\n",
    "mean_stats = defaultdict(lambda : defaultdict(list))\n",
    "for name in stats:\n",
    "    base_name = \" \".join(name.split(\"_\")[:2])\n",
    "    mean_stats[base_name][\"test_loss\"].append(stats[name][\"test_loss\"])\n",
    "    mean_stats[base_name][\"test_rel\"].append(np.mean(stats[name][\"test_rel\"]))\n",
    "\n",
    "    errors = stats[name][\"test_errors\"]\n",
    "    for threshold in thresholds:\n",
    "        mean_stats[base_name][f\"test_acc_{threshold}\"].append(np.mean(errors < threshold))\n",
    "    \n",
    "    \n",
    "\n",
    "for name in mean_stats:\n",
    "    mean_stats[name][\"test_errors\"] = np.mean(mean_stats[name][\"test_errors\"])\n",
    "    mean_stats[name][\"test_rel\"] = np.mean(mean_stats[name][\"test_rel\"])\n",
    "    mean_stats[name][\"test_loss\"] = np.mean(mean_stats[name][\"test_loss\"])\n",
    "    for threshold in thresholds:\n",
    "        mean_stats[name][f\"test_acc_{threshold}\"] = np.mean(mean_stats[name][f\"test_acc_{threshold}\"])\n",
    "\n",
    "\n",
    "for name in sorted(mean_stats):\n",
    "    print(f\"test_loss\\t{name}:\\t{mean_stats[name]['test_loss']:.4f}\")\n",
    "    print(f\"test_rel\\t{name}:\\t{mean_stats[name]['test_rel']:.4f}\")\n",
    "    for threshold in thresholds:\n",
    "        key = f\"test_acc_{threshold}\"\n",
    "        print(f\"{key}\\t{name}:\\t{mean_stats[name][key]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &  loss &   rel &  delta < 1.25 &  delta < 1.25\\textasciicircum 2 &  delta < 1.25\\textasciicircum 3 \\\\\n",
      "\\midrule\n",
      "contrastive probing       & 0.814 & 0.266 &         0.566 &           0.856 &           0.954 \\\\\n",
      "classification probing    & 0.846 & 0.245 &         0.554 &           0.855 &           0.959 \\\\\n",
      "contrastive switch        & 0.570 & 0.210 &         0.663 &           0.914 &           0.979 \\\\\n",
      "contrastive finetuning    & 0.479 & 0.190 &         0.704 &           0.935 &           0.987 \\\\\n",
      "classification switch     & 0.460 & 0.183 &         0.713 &           0.941 &           0.987 \\\\\n",
      "classification finetuning & 0.412 & 0.178 &         0.744 &           0.948 &           0.989 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1335648/1559691029.py:10: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.to_latex(index=True, float_format=\"%.3f\"))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(mean_stats).T\n",
    "# drop col test_errors\n",
    "df = df.drop(\"test_errors\", axis=1)\n",
    "df.columns = [\"loss\", \"rel\", \"delta < 1.25\", \"delta < 1.25^2\", \"delta < 1.25^3\"]\n",
    "# sort by rel desc\n",
    "df = df.sort_values(\"rel\", ascending=False)\n",
    "df.to_csv(\"results/metrics.csv\")\n",
    "# print in latex with 3 decimal places\n",
    "print(df.to_latex(index=True, float_format=\"%.3f\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7781f5385b8eb849e784f16227eb820bfbe419dd7b5cb8ef58d25c8acbf987c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('testenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
